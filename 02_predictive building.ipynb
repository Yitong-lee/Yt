import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

import tensorflow as tf
from tensorflow import keras

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("train_cleaned.csv")
X = df.drop(['reviewer_ID', 'fake_asin', 'product_ID', 'review_ID', 'review', 'fake_review'], axis = 1)

# get dummies
X = pd.get_dummies(X, columns=['labeled_product_id'])
X = X.drop(['labeled_product_id_0'], axis = 1)

# scaling
X = X.apply(pd.to_numeric)
stander = StandardScaler()

X = stander.fit_transform(X)
y = df['fake_review']

model = keras.models.Sequential()


model.add(keras.layers.Dense(2048, activation='relu', input_dim=X.shape[1]))

model.add(keras.layers.Dense(1024, activation='relu'))

model.add(keras.layers.Dense(512, activation='relu'))

model.add(keras.layers.Dense(256, activation='relu'))

model.add(keras.layers.Dense(128, activation='relu'))

model.add(keras.layers.Dense(1, activation='sigmoid')) 

model.compile(loss=keras.losses.BinaryFocalCrossentropy(), optimizer='adam', metrics=['accuracy'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 12343)

# compute the class weights
n_samples = len(y_train)
n_classes = len(np.unique(y_train))
class_counts = np.bincount(y_train)
class_weights = {i: n_samples / (n_classes * class_counts[i]) for i in range(n_classes)}

# fit the model with sample weights
sample_weights = np.array([class_weights[label] for label in y_train])

from keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')

model.fit(X_train, y_train, sample_weight=sample_weights, epochs = 50, validation_split=0.2, batch_size=64)

from sklearn.metrics import confusion_matrix
# Get the predicted labels and true labels
y_pred = model.predict(X_test)

def my_fuc(x):
    if x < 0.65:
        return 0
    else:
        return 1
    
y_pred = np.array([my_fuc(x) for x in y_pred])

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Print the confusion matrix
print(cm)

from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred))

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

df_test = pd.read_csv("test_cleaned.csv")
df_test_sample = df_test.drop(['reviewer_ID', 'product_ID', 'review_ID', 'review', 'fake_asin'], axis = 1)

df_test_sample = pd.get_dummies(df_test_sample, columns=['labeled_product_id'])
df_test_sample = df_test_sample.drop(['labeled_product_id_0'], axis = 1)

stander = StandardScaler()
df_test_sample = stander.fit_transform(df_test_sample)
df_test_sample
predictions = model.predict(df_test_sample)
df_test["fake_review"] = predictions
output = df_test[["review_ID", "fake_review"]]
output['fake_review'] = output['fake_review'].apply(lambda x: 0 if x < 0.65 else 1)
output.to_csv('result.csv', index=False)
